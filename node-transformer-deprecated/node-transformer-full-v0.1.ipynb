{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version 1.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchdiffeq\n",
    "\n",
    "from tensorboard_utils import Tensorboard\n",
    "from tensorboard_utils import tensorboard_event_accumulator\n",
    "\n",
    "import transformer.Constants as Constants\n",
    "from transformer.Layers import EncoderLayer, DecoderLayer\n",
    "from transformer.Modules import ScaledDotProductAttention\n",
    "from transformer.Models import Decoder, get_attn_key_pad_mask, get_non_pad_mask, get_sinusoid_encoding_table\n",
    "from transformer.SubLayers import PositionwiseFeedForward\n",
    "\n",
    "import dataset\n",
    "\n",
    "import model_process\n",
    "import checkpoints\n",
    "from node_transformer import NodeTransformer\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook  \n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "print(\"Torch Version\", torch.__version__)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\")\n",
    "print(\"device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(\"/home/mandubian/datasets/multi30k/multi30k.atok.low.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "max_token_seq_len = data['settings'].max_token_seq_len\n",
    "print(max_token_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = dataset.prepare_dataloaders(data, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment with a name and a unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"node_transformer_full_multi30k\"\n",
    "unique_id = \"2019-06-08_1300\"\n",
    "\n",
    "# unique_id = \"2019-06-05_1300\"\n",
    "# default\n",
    "# batch 128\n",
    "# rtol=1e-3, atol=1e-3\n",
    "# lr=1e-5\n",
    "\n",
    "# unique_id = \"2019-06-07_2100\"\n",
    "# default\n",
    "# batch 128\n",
    "# d_word_vec=64, d_model=64, d_inner=256,\n",
    "# n_head=4, method='dopri5-ext', rtol=1e-2, atol=1e-2\n",
    "# lr=1e-4\n",
    "\n",
    "# unique_id = \"2019-06-08_1300\"\n",
    "# default\n",
    "# batch 128\n",
    "# rtol=1e-2, atol=1e-2\n",
    "# lr=1e-4\n",
    "# progressive depth: 2 (25)\n",
    "# 0-12: depth 2\n",
    "# 12-x: depth 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_vocab_sz 9795\n",
      "tgt_vocab_sz 17989\n"
     ]
    }
   ],
   "source": [
    "\n",
    "src_vocab_sz = train_loader.dataset.src_vocab_size\n",
    "print(\"src_vocab_sz\", src_vocab_sz)\n",
    "tgt_vocab_sz = train_loader.dataset.tgt_vocab_size\n",
    "print(\"tgt_vocab_sz\", tgt_vocab_sz)\n",
    "\n",
    "if model:\n",
    "    del model\n",
    "    \n",
    "model = NodeTransformer(\n",
    "    n_src_vocab=max(src_vocab_sz, tgt_vocab_sz),\n",
    "    n_tgt_vocab=max(src_vocab_sz, tgt_vocab_sz),\n",
    "    len_max_seq=max_token_seq_len,\n",
    "    #emb_src_tgt_weight_sharing=False,\n",
    "    #d_word_vec=64, d_model=64, d_inner=256,\n",
    "    n_head=8, method='dopri5-ext', rtol=1e-2, atol=1e-2,\n",
    "    has_node_encoder=True, has_node_decoder=True)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tensorboard metrics logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing TensorBoard events locally to runs/node_transformer_full_multi30k_2019-06-08_1300\n"
     ]
    }
   ],
   "source": [
    "tb = Tensorboard(exp_name, unique_name=unique_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create basic optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.995), eps=1e-9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model and timesteps to cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a62e7ce1784baaac56d9c40fdb28f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=50, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb749b4b87cd4675bd23e43077914264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 19', max=227, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch 19 ]\n",
      "Adding group train to writers (dict_keys([]))\n",
      "[Training]  loss: 5.9475882889758935, ppl:  382.82895, accuracy: 41.752 %, elapse: 1720832.954ms\n",
      "Adding group eval to writers (dict_keys(['train']))\n",
      "[Validation]  loss: 5.292197378259546,  ppl:  198.77974, accuracy: 43.735 %, elapse: 2922.706ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462a4ca4ae5c41f8960595dcce18a596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 20', max=227, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch 20 ]\n",
      "[Training]  loss: 5.824254621632849, ppl:  338.40880, accuracy: 42.521 %, elapse: 1749549.291ms\n",
      "[Validation]  loss: 5.302833507392184,  ppl:  200.90527, accuracy: 43.241 %, elapse: 2916.893ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15605c58489049b3add2f109c6151daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 21', max=227, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch 21 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6a00cc92ba57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOG_INTERVAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_valid_accu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;32m~/notebooks/pytorch-neural-ode/model_process.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(exp_name, unique_id, model, training_data, validation_data, timesteps, optimizer, device, epochs, tb, log_interval, start_epoch, best_valid_accu, best_valid_loss)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     print('[Training]  loss: {train_loss}, ppl: {ppl: 8.5f}, accuracy: {accu:3.3f} %, '\\\n\u001b[1;32m    151\u001b[0m           'elapse: {elapse:3.3f}ms'.format(\n",
      "\u001b[0;32m~/notebooks/pytorch-neural-ode/model_process.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, training_data, timesteps, optimizer, device, epoch, pb, tb, log_interval)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_as\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_as\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Continuous space discretization\n",
    "timesteps = np.linspace(0., 1, num=6)\n",
    "timesteps = torch.from_numpy(timesteps).float()\n",
    "\n",
    "EPOCHS = 50\n",
    "LOG_INTERVAL = 5\n",
    "\n",
    "#from torch import autograd\n",
    "#with autograd.detect_anomaly():\n",
    "model_process.train(\n",
    "    exp_name, unique_id,\n",
    "    model, \n",
    "    train_loader, val_loader, timesteps,\n",
    "    optimizer, device,\n",
    "    epochs=EPOCHS, tb=tb, log_interval=LOG_INTERVAL,\n",
    "    start_epoch=19, best_valid_accu=state[\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model and timesteps to cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a566476a4f44e484b1cbac239a2973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=50, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b813c44a7dfd40d897ae899a4a64ca9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 21', max=227, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch 21 ]\n",
      "[Training]  loss: 5.982365558516917, ppl:  396.37691, accuracy: 41.378 %, elapse: 2633471.951ms\n",
      "[Validation]  loss: 5.288381585692922,  ppl:  198.02268, accuracy: 43.463 %, elapse: 2984.516ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d54151ccef41a084ed3ddbc2307d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 22', max=227, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch 22 ]\n"
     ]
    }
   ],
   "source": [
    "# Continuous space discretization\n",
    "timesteps = np.linspace(0., 1, num=12)\n",
    "timesteps = torch.from_numpy(timesteps).float()\n",
    "\n",
    "EPOCHS = 50\n",
    "LOG_INTERVAL = 5\n",
    "\n",
    "#from torch import autograd\n",
    "#with autograd.detect_anomaly():\n",
    "model_process.train(\n",
    "    exp_name, unique_id,\n",
    "    model, \n",
    "    train_loader, val_loader, timesteps,\n",
    "    optimizer, device,\n",
    "    epochs=EPOCHS, tb=tb, log_interval=LOG_INTERVAL,\n",
    "    start_epoch=21, best_valid_accu=state[\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore best checkpoint (to restart past training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting state from checkpoints/node_transformer_full_multi30k_2019-06-08_1300_validation_best.pth\n",
      "Loading model state_dict from state found in checkpoints/node_transformer_full_multi30k_2019-06-08_1300_validation_best.pth\n",
      "Loading optimizer state_dict from state found in checkpoints/node_transformer_full_multi30k_2019-06-08_1300_validation_best.pth\n",
      "accuracy 0.4476681710724264\n",
      "loss 5.363942295853034\n"
     ]
    }
   ],
   "source": [
    "state = checkpoints.restore_best_checkpoint(\n",
    "    exp_name, unique_id, \"validation\", model, optimizer)\n",
    "\n",
    "print(\"accuracy\", state[\"acc\"])\n",
    "print(\"loss\", state[\"loss\"])\n",
    "model = model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
