{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version 1.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./fairseq\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "\n",
    "from fairseq import checkpoint_utils, distributed_utils, options, progress_bar, tasks, utils\n",
    "from fairseq.data import iterators\n",
    "from fairseq.trainer import Trainer\n",
    "from fairseq.meters import AverageMeter, StopwatchMeter\n",
    "\n",
    "from node_transformer import node_transformer, node_trainer\n",
    "\n",
    "print(\"Torch Version\", torch.__version__)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='node_transformer', attention_dropout=0.0, bucket_cap_mb=25, clip_norm=25, cpu=False, criterion='cross_entropy', curriculum=0, data='/home/mandubian/notebooks/pytorch-neural-ode/node-transformer-fair/fairseq/examples/translation/data-bin/iwslt14.tokenized.de-en', dataset_impl='cached', ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layers=1, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layers=1, encoder_learned_pos=False, encoder_normalize_before=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, global_sync_iter=10, keep_interval_updates=10, keep_last_epochs=10, lazy_load=False, left_pad_source='True', left_pad_target='False', log_format='tqdm', log_interval=1000, lr=[0.001], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=16000, max_update=0, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_epoch_checkpoints=False, no_progress_bar=False, no_save=False, no_token_positional_embeddings=False, node_atol=0.01, node_augment_dims=1, node_decoder=True, node_encoder=False, node_max_num_steps=1000, node_method='dopri5-ext', node_rtol=0.01, node_separated_decoder=True, node_time_dependent=False, node_ts=[0.0, 1.0], num_workers=8, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/node_transformer_decoder_only_aug_1_sep_weight_decay_20190806_1600', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='de', target_lang='en', task='translation', tbmf_wrapper=False, tensorboard_logdir='./runs/node_transformer_decoder_only_aug_1_sep_weight_decay_20190806_1600', threshold_loss_scale=None, tie_adaptive_weights=False, train_subset='train', update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_updates=0, weight_decay=0.9)\n"
     ]
    }
   ],
   "source": [
    "#EXP_ID=\"transformer_20190703_1800\"\n",
    "#| Generate test with beam=5: BLEU4 = 26.76, 62.4/34.6/21.0/13.1 (BP=0.965, ratio=0.966, syslen=126657, reflen=131161)\n",
    "\n",
    "\n",
    "#EXP_ID=\"node_transformer_20190703_2230\"\n",
    "#| Generate test with beam=5: BLEU4 = 22.77, 57.3/29.4/16.6/9.7 (BP=1.000, ratio=1.009, syslen=132351, reflen=131161)\n",
    "\n",
    "\n",
    "#EXP_ID=\"transformer_encoder_1layer_20190704_1000\"\n",
    "#| Generate test with beam=5: BLEU4 = 24.76, 60.5/32.2/18.7/11.3 (BP=0.978, ratio=0.978, syslen=128254, reflen=131161)\n",
    "\n",
    "\n",
    "# EXP_ID=\"transformer_decoder_1layer_20190710_1530\"\n",
    "# lr = 0.01 epoch 0-27 (nfe infinite at epoch 27) ??? (not sure anymore :D)\n",
    "# lr = 0.001 epoch 28-...\n",
    "\n",
    "\n",
    "#EXP_ID=\"node_transformer_aug_time_dep_20190710_2300\"\n",
    "# encoder 1 layer transformer\n",
    "# lr = 0.001\n",
    "# rtol/atol = 0.01\n",
    "# SUFFIX = \"_1\"\n",
    "# SUB_EXP_ID=\"node_transformer_aug_time_dep_20190710_2300_1\"\n",
    "# lr = 0.001\n",
    "# adam\n",
    "# rtol/atol = 0.005\n",
    "\n",
    "\n",
    "#EXP_ID=\"transformer_encoder_decoder_1layer_20190716_0900\"\n",
    "#SUFFIX=\"\"\n",
    "# encoder/decoder 1 layer transformer\n",
    "# lr = 0.001\n",
    "\n",
    "#EXP_ID=\"node_transformer_separated_decoder_20190716_2100\"\n",
    "#SUFFIX=\"_1\"\n",
    "# separated node_decoder 1 layer - encoder 1 layer\n",
    "# rtol/atol = 0.1 then 0.01\n",
    "# lr = 0.0001\n",
    "\n",
    "#EXP_ID=\"node_transformer_separated_decoder_aug_4_20190718_0000\"\n",
    "# rtol/atol = 0.0005\n",
    "# lr = 0.001 then 0.0005\n",
    "#SUFFIX=\"_1\"\n",
    "\n",
    "#EXP_ID=\"node_transformer_separated_decoder_aug_1_2_layers_20190719_1030\"\n",
    "\n",
    "#EXP_ID=\"node_transformer_separated_decoder_aug_1_layer_learned_pos_20190727_1330\"\n",
    "\n",
    "#EXP_ID=\"node_transformer_separated_decoder_aug_5_weight_decay_20190729_0000\"\n",
    "# weight-decay = 0.9, rtol=0.001\n",
    "\n",
    "#EXP_ID=\"node_transformer_full_separated_aug_1_weight_decay_20190731_0000\"\n",
    "\n",
    "#EXP_ID=\"node_transformer_full_201900801_1100\"\n",
    "\n",
    "#EXP_ID=\"node_transformer_full_aug_1_20190804_0030\"\n",
    "# rtol/atol 0.01\n",
    "\n",
    "#EXP_ID=\"node_transformer_full_aug_1_20190804_0430\"\n",
    "# rtol/atol 0.001\n",
    "\n",
    "#EXP_ID=\"node_transformer_decoder_only_20190805_0000\"\n",
    "# rtol/atol 0.001\n",
    "\n",
    "#EXP_ID=\"node_transformer_decoder_only_aug_1_20190805_1400\"\n",
    "# rtol/atol 0.001\n",
    "\n",
    "#EXP_ID=\"node_transformer_decoder_only_aug_1_20190805_2130\"\n",
    "# rtol/atol 0.01\n",
    "\n",
    "#EXP_ID=\"node_transformer_decoder_only_aug_1_time_dep_20190806_0830\"\n",
    "# separated\n",
    "# rtol/atol 0.01\n",
    "\n",
    "#EXP_ID=\"node_transformer_decoder_only_aug_1_20190806_1230\"\n",
    "# separated\n",
    "# rtol/atol 0.01\n",
    "\n",
    "\n",
    "EXP_ID=\"node_transformer_decoder_only_aug_1_sep_weight_decay_20190806_1600\"\n",
    "# separated weight decay\n",
    "# rtol/atol 0.01\n",
    "\n",
    "\n",
    "SUFFIX=\"\"\n",
    "args = [\n",
    "    #\"/home/mandubian/notebooks/pytorch-neural-ode/node-transformer-fair/fairseq/examples/translation/data-bin/wmt14_en_fr\",\n",
    "    \"/home/mandubian/notebooks/pytorch-neural-ode/node-transformer-fair/fairseq/examples/translation/data-bin/iwslt14.tokenized.de-en\",\n",
    "    #\"--arch\", \"node_transformer_wmt_en_fr\",\n",
    "    \"--arch\", \"node_transformer\",\n",
    "    #\"--arch\", \"transformer_iwslt_de_en\",\n",
    "    \"--task\", \"translation\",\n",
    "    \"--source-lang\", \"de\",\n",
    "    \"--target-lang\", \"en\",\n",
    "    # NODE PARAMS BEGIN\n",
    "    #\"--node-encoder\",\n",
    "    \"--node-decoder\",\n",
    "    \"--node-rtol\", \"0.01\",\n",
    "    \"--node-atol\", \"0.01\",\n",
    "    #\"--node-rtol\", \"0.0005\",\n",
    "    #\"--node-atol\", \"0.0005\",\n",
    "    \"--node-ts\", \"[0.0, 1.0]\",\n",
    "    \"--node-augment-dims\", \"1\",\n",
    "    #\"--node-time-dependent\",\n",
    "    \"--node-separated-decoder\",\n",
    "    # NODE PARAMS END    \n",
    "    \"--log-format\", \"tqdm\",\n",
    "    \"--max-tokens\", \"16000\",\n",
    "    #\"--max-sentences\", \"1000\",\n",
    "    \"--num-workers\", \"8\",\n",
    "    #\"--dataset-impl\", \"lazy\",\n",
    "    \"--criterion\", \"cross_entropy\",\n",
    "    #\"--label-smoothing\", \"0.1\",\n",
    "    \"--lr\", \"0.001\",\n",
    "    #\"--lr\", \"0.0001\",\n",
    "    \"--optimizer\", \"adam\",\n",
    "    \"--weight-decay\", \"0.9\",\n",
    "    #\"--lr-scheduler\", \"inverse_sqrt\",\n",
    "    \"--save-dir\", f\"checkpoints/{EXP_ID}{SUFFIX}\",\n",
    "    \"--tensorboard-logdir\", f\"./runs/{EXP_ID}{SUFFIX}\",\n",
    "    \"--keep-interval-updates\", \"10\",\n",
    "    \"--restore-file\", \"checkpoint_last.pt\",\n",
    "    \"--keep-last-epochs\", \"10\",\n",
    "    \"--encoder-layers\", \"1\",\n",
    "    \"--decoder-layers\", \"1\",\n",
    "    #\"--decoder-learned-pos\",\n",
    "]\n",
    "parser = options.get_training_parser()\n",
    "#add_node_args(parser)\n",
    "args = options.parse_args_and_arch(parser, input_args=args)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUDA device 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() and not args.cpu:\n",
    "    print(\"using CUDA device\", args.device_id)\n",
    "    torch.cuda.set_device(args.device_id)\n",
    "_ = torch.manual_seed(args.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| [de] dictionary: 8848 types\n",
      "| [en] dictionary: 6632 types\n"
     ]
    }
   ],
   "source": [
    "# Setup task, e.g., translation, language modeling, etc.\n",
    "task = tasks.setup_task(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| /home/mandubian/notebooks/pytorch-neural-ode/node-transformer-fair/fairseq/examples/translation/data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples\n"
     ]
    }
   ],
   "source": [
    "# Load valid dataset (we load training data below, based on the latest checkpoint)\n",
    "for valid_sub_split in args.valid_subset.split(','):\n",
    "    task.load_dataset(valid_sub_split, combine=True, epoch=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NodeTransformerModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embed_tokens): Embedding(8848, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): NodeTransformerDecoder(\n",
      "    (embed_tokens): Embedding(6632, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): NodeTransformerDecoderLayer_Separated(\n",
      "        (func_self_attn): TransformerDecoderLayerFunc_SelfAttn(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (func_ode): NodeTransformerDecoderLayerFunc_EncoderAttn(\n",
      "          (encoder_attn): MultiheadAttention(\n",
      "            (out_proj): Linear(in_features=520, out_features=520, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm(torch.Size([520]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=520, out_features=2048, bias=True)\n",
      "          (fc2): Linear(in_features=2048, out_features=520, bias=True)\n",
      "          (final_layer_norm): LayerNorm(torch.Size([520]), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=520, out_features=520, bias=True)\n",
      "        (final_layer_norm): LayerNorm(torch.Size([520]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (project_out_dim): Linear(in_features=520, out_features=512, bias=False)\n",
      "  )\n",
      ")\n",
      "| model node_transformer, criterion CrossEntropyCriterion\n",
      "| num. model params: 19281824 (num. trained: 19281824)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build model and criterion\n",
    "model = task.build_model(args)\n",
    "criterion = task.build_criterion(args)\n",
    "print(model)\n",
    "print('| model {}, criterion {}'.format(args.arch, criterion.__class__.__name__))\n",
    "print('| num. model params: {} (num. trained: {})'.format(\n",
    "    sum(p.numel() for p in model.parameters()),\n",
    "    sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| training on 1 GPUs\n",
      "| max tokens per GPU = 16000 and max sentences per GPU = None\n"
     ]
    }
   ],
   "source": [
    "# Build trainer\n",
    "trainer = node_trainer.Trainer(args, task, model, criterion)\n",
    "print('| training on {} GPUs'.format(args.distributed_world_size))\n",
    "print('| max tokens per GPU = {} and max sentences per GPU = {}'.format(\n",
    "    args.max_tokens,\n",
    "    args.max_sentences,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| loaded checkpoint checkpoints/node_transformer_decoder_only_aug_1_sep_weight_decay_20190806_1600/checkpoint_last.pt (epoch 8 @ 2360 updates)\n",
      "| loading train data for epoch 8\n",
      "| /home/mandubian/notebooks/pytorch-neural-ode/node-transformer-fair/fairseq/examples/translation/data-bin/iwslt14.tokenized.de-en train de-en 160239 examples\n"
     ]
    }
   ],
   "source": [
    "## Load the latest checkpoint if one is available and restore the\n",
    "# corresponding train iterator\n",
    "#save_dir_keep = args.save_dir\n",
    "#args.save_dir = f\"checkpoints/{EXP_ID}{SUFFIX}\"\n",
    "#args.reset_optimizer = True\n",
    "extra_state, epoch_itr = checkpoint_utils.load_checkpoint(args, trainer)\n",
    "#args.save_dir = save_dir_keep\n",
    "#args.reset_optimizer = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 009 | loss 4.831 | ppl 28.45 | wps 3216 | ups 0 | wpb 13386.827 | bsz 543.183 | num_updates 2655 | lr 0.001 | gnorm 0.904 | clip 0.000 | oom 0.000 | wall 1232 | train_wall 8623 | nfe_decoder 76.986\n",
      "| epoch 009 | valid on 'valid' subset | loss 4.850 | ppl 28.84 | num_updates 2655 | best_loss 4.84989\n",
      "| saved checkpoint checkpoints/node_transformer_decoder_only_aug_1_sep_weight_decay_20190806_1600/checkpoint9.pt (epoch 9 @ 2655 updates) (writing took 0.7941689491271973 seconds)\n",
      "| epoch 011 | loss 4.710 | ppl 26.17 | wps 3584 | ups 0 | wpb 13386.827 | bsz 543.183 | num_updates 3245 | lr 0.001 | gnorm 0.949 | clip 0.000 | oom 0.000 | wall 3589 | train_wall 10958 | nfe_decoder 79.507\n",
      "| epoch 011 | valid on 'valid' subset | loss 4.782 | ppl 27.51 | num_updates 3245 | best_loss 4.78178\n",
      "| saved checkpoint checkpoints/node_transformer_decoder_only_aug_1_sep_weight_decay_20190806_1600/checkpoint11.pt (epoch 11 @ 3245 updates) (writing took 0.42360806465148926 seconds)\n",
      "| epoch 012 | loss 4.635 | ppl 24.85 | wps 3470 | ups 0 | wpb 13386.827 | bsz 543.183 | num_updates 3540 | lr 0.001 | gnorm 0.940 | clip 0.000 | oom 0.000 | wall 4736 | train_wall 12094 | nfe_decoder 80.288\n",
      "| epoch 012 | valid on 'valid' subset | loss 4.918 | ppl 30.24 | num_updates 3540 | best_loss 4.78178\n",
      "| saved checkpoint checkpoints/node_transformer_decoder_only_aug_1_sep_weight_decay_20190806_1600/checkpoint12.pt (epoch 12 @ 3540 updates) (writing took 0.46453118324279785 seconds)\n"
     ]
    }
   ],
   "source": [
    "from train import validate\n",
    "\n",
    "def train(args, trainer, task, epoch_itr):\n",
    "    \"\"\"Train the model for one epoch.\"\"\"\n",
    "    # Update parameters every N batches\n",
    "    update_freq = args.update_freq[epoch_itr.epoch - 1] \\\n",
    "        if epoch_itr.epoch <= len(args.update_freq) else args.update_freq[-1]\n",
    "\n",
    "    # Initialize data iterator\n",
    "    itr = epoch_itr.next_epoch_itr(\n",
    "        fix_batches_to_gpus=args.fix_batches_to_gpus,\n",
    "        shuffle=(epoch_itr.epoch >= args.curriculum),\n",
    "    )\n",
    "    itr = iterators.GroupedIterator(itr, update_freq)\n",
    "    progress = progress_bar.build_progress_bar(\n",
    "        args, itr, epoch_itr.epoch, no_progress_bar='simple',\n",
    "    )\n",
    "\n",
    "    extra_meters = collections.defaultdict(lambda: AverageMeter())\n",
    "    valid_subsets = args.valid_subset.split(',')\n",
    "    max_update = args.max_update or math.inf\n",
    "    \n",
    "    #timesteps = torch.FloatTensor(args.ts).to()\n",
    "    for i, samples in enumerate(progress, start=epoch_itr.iterations_in_epoch):\n",
    "        log_output = trainer.train_step(samples)\n",
    "        if log_output is None:\n",
    "            continue\n",
    "\n",
    "        # log mid-epoch stats\n",
    "        stats = get_training_stats(trainer)\n",
    "        for k, v in log_output.items():\n",
    "            if k in ['loss', 'nll_loss', 'ntokens', 'nsentences', 'sample_size']:\n",
    "                continue  # these are already logged above\n",
    "            if 'loss' in k:\n",
    "                extra_meters[k].update(v, log_output['sample_size'])\n",
    "            else:\n",
    "                extra_meters[k].update(v)\n",
    "            stats[k] = extra_meters[k].avg\n",
    "        progress.log(stats, tag='train', step=stats['num_updates'])\n",
    "\n",
    "        # ignore the first mini-batch in words-per-second calculation\n",
    "        if i == 0:\n",
    "            trainer.get_meter('wps').reset()\n",
    "\n",
    "        num_updates = trainer.get_num_updates()\n",
    "        if (\n",
    "            not args.disable_validation\n",
    "            and args.save_interval_updates > 0\n",
    "            and num_updates % args.save_interval_updates == 0\n",
    "            and num_updates > 0\n",
    "        ):\n",
    "            valid_losses = validate(args, trainer, task, epoch_itr, valid_subsets)\n",
    "            checkpoint_utils.save_checkpoint(args, trainer, epoch_itr, valid_losses[0])\n",
    "\n",
    "        if num_updates >= max_update:\n",
    "            break\n",
    "\n",
    "    # log end-of-epoch stats\n",
    "    stats = get_training_stats(trainer)\n",
    "    for k, meter in extra_meters.items():\n",
    "        stats[k] = meter.avg\n",
    "    progress.print(stats, tag='train', step=stats['num_updates'])\n",
    "\n",
    "    # reset training meters\n",
    "    for k in [\n",
    "        'train_loss', 'train_nll_loss', 'wps', 'ups', 'wpb', 'bsz', 'gnorm', 'clip',\n",
    "    ]:\n",
    "        meter = trainer.get_meter(k)\n",
    "        if meter is not None:\n",
    "            meter.reset()\n",
    "\n",
    "\n",
    "def get_training_stats(trainer):\n",
    "    stats = collections.OrderedDict()\n",
    "    stats['loss'] = trainer.get_meter('train_loss')\n",
    "    if trainer.get_meter('train_nll_loss').count > 0:\n",
    "        nll_loss = trainer.get_meter('train_nll_loss')\n",
    "        stats['nll_loss'] = nll_loss\n",
    "    else:\n",
    "        nll_loss = trainer.get_meter('train_loss')\n",
    "    stats['ppl'] = utils.get_perplexity(nll_loss.avg)\n",
    "    stats['wps'] = trainer.get_meter('wps')\n",
    "    stats['ups'] = trainer.get_meter('ups')\n",
    "    stats['wpb'] = trainer.get_meter('wpb')\n",
    "    stats['bsz'] = trainer.get_meter('bsz')\n",
    "    stats['num_updates'] = trainer.get_num_updates()\n",
    "    stats['lr'] = trainer.get_lr()\n",
    "    stats['gnorm'] = trainer.get_meter('gnorm')\n",
    "    stats['clip'] = trainer.get_meter('clip')\n",
    "    stats['oom'] = trainer.get_meter('oom')\n",
    "    if trainer.get_meter('loss_scale') is not None:\n",
    "        stats['loss_scale'] = trainer.get_meter('loss_scale')\n",
    "    stats['wall'] = round(trainer.get_meter('wall').elapsed_time)\n",
    "    stats['train_wall'] = trainer.get_meter('train_wall')\n",
    "    if trainer._model.has_node_encoder:\n",
    "        stats['nfe_encoder'] = trainer.get_meter('nfe_encoder')\n",
    "    if trainer._model.has_node_decoder:\n",
    "        stats['nfe_decoder'] = trainer.get_meter('nfe_decoder')\n",
    "    return stats\n",
    "\n",
    "\n",
    "\n",
    "# Train until the learning rate gets too small\n",
    "max_epoch = args.max_epoch or math.inf\n",
    "max_update = args.max_update or math.inf\n",
    "lr = trainer.get_lr()\n",
    "train_meter = StopwatchMeter()\n",
    "train_meter.start()\n",
    "valid_losses = [None]\n",
    "valid_subsets = args.valid_subset.split(',')\n",
    "while lr > args.min_lr and epoch_itr.epoch < max_epoch and trainer.get_num_updates() < max_update:\n",
    "    # train for one epoch\n",
    "    train(args, trainer, task, epoch_itr)\n",
    "\n",
    "    if not args.disable_validation and epoch_itr.epoch % args.validate_interval == 0:\n",
    "        valid_losses = validate(args, trainer, task, epoch_itr, valid_subsets)\n",
    "    else:\n",
    "        valid_losses = [None]\n",
    "\n",
    "    # only use first validation loss to update the learning rate\n",
    "    lr = trainer.lr_step(epoch_itr.epoch, valid_losses[0])\n",
    "\n",
    "    # save checkpoint\n",
    "    if epoch_itr.epoch % args.save_interval == 0:\n",
    "        checkpoint_utils.save_checkpoint(args, trainer, epoch_itr, valid_losses[0])\n",
    "\n",
    "    if ':' in getattr(args, 'data', ''):\n",
    "        # sharded data: get train iterator for next epoch\n",
    "        epoch_itr = trainer.get_train_iterator(epoch_itr.epoch)\n",
    "train_meter.stop()\n",
    "print('| done training in {:.1f} seconds'.format(train_meter.sum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
